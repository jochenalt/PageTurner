Mein Projekt ist ein Pageturner für ein Klavier.

I will use a  teensy 4.1, a teensy audio shield und ein max9814 (adafruit). The page turner has a usb-C interface (Teensies original USB port) that is connected to a tablet showing music sheets and acts as a HID interface producing PAGE_UP and PAGE_DN events. I want to train the words "next", "weiter", "zurück", and "back". 

The main libraries I want to use is Tensorflow Lite micro with the embedded MFCC features. I will use PlatformIO.

These are the main usecases:
- Usecase "recording". Recording one word of training data. To start that, I will push a button on the PCB. An red "on air" LED on the PCB will light up, and this will make the teensy to record audio data during the button is pressed. At the same time, the audio stream is sent to a connected PC via the serial interface. When releasing the button, the recording stops, so does sending the audio stream to the PC.
On the PC, the data is received via Python and used for training a tensorflow later on. Once the input stream from the teensy stops (after a timeout of 2.0s), the python program should convert the audio stream into .wav file and play it over the PC's speaker. Aftwards, the python program is waiting for the next recording. The incoming audio stream is converted into wav files placed an data structure like "next/next1.wav", "back/back1.wav" plus a folder for background noise, silence, and unknown. To determine this, the menu has a mode called "recording mode" which can have the states (next, back, weiter, zurück, silence, background). The menu allows to set this mode, such that the file names can be assigned properly. The file structure should be defined such that Tensorflow Speech Commands can pick up all files correctly. The audio stream should have a simple checksum validation that is interpreted and validated on the PC side as well. 

- usecase "testing"
  The PC can be in testing mode (set by the menu). In that mode, the Teensy acts like in the recording mode, but the PC does not use the audio snippet for training but runs inference with the current model on the PC side and display the identified category. PC uses same preprocessing stack for inference as training and Teensy.


- usecase "training"
The python programm should also listen to its local keyboard and display a ascii-help menu on the console when it starts. When receiving an audio stream is received, an according message is shown. The help menu allows to go in the training mode by pressing "t" on the keyboard. This will trigger the training and create a model in a file in the folder /model. The menu will also allow to play all files in /dataset/*.wav  in a row while displaying the filename. 

- usecase "transfer model"
The menu in the python program allows to upload the model to the teensy after pressing "u" . The teensy will receive the model via the serial line and stores it on the Teensy's SD card, and deletes the previous model. While this  happens, a yellow LED on the PCB is lighting up. Afterwards, the Teensy sends a message back to the Python program confirming the new model. The python programm displays this confirmation and goes back to waiting for commands as listed in the help menu. The transfer should be secured with a checksum that created on the pc side and validated on the Teensy. Of course the checksum needs to be removed before storing the model on the sd-card. 

- usecase "listening"
In this usecase, the Teensy is connected to the tablet, and a green LED is lighting up. This mode is the default, unless no model is present. In that case, the green LED is off and the teensy can only record audio, or receive a model. This mode could be interrupted by pushing the recording button or by receiving a new model. In the listening mode, the mic is constantly streaming and processes via TFLM  with embedded MVCC capability. When one of the key words "next", "back", "weiter", "zurück", "silence", "background" is identified, PAGE-UP or Page-DN is generated and send to the tablet via HID. Take care that the tensorflow model created on the PC is compatible with the TFLM model on the Teensy.

The PCB consists of Teensy 4.1, the teensy audio board,  three LEDs and one  button:
 - red LED  when recording to the PC is happening 
 - green LED for default listening mode
 - yellow LED for uploading a model from the PC
 - button triggering recording mode and sending it to the PC. 
 - Another Serial port of the Teensy is used for debug output, i.e. it is connected to a different USB port of the PC (via a serial2USB converter). All actions happening in the Teensy are logged there. Logging is not saved but only visualised in a terminal on the PC

Additional concepts:
- the recording usecase takes 16-bit PCM mono, sapling rate 16kHz
- MFCC windowing: window size = 30ms, stride 10ms, number of MFCCs=13
- length of each recording sample is 2s.
- Transmission framing: the packet structure when sending audio over serial is [2 bytes header character(magic number)][payload-length][payload][CRC-8].
- bidirectional protocol between Teensy and PC supports these header commands: RECORDING_START, RECORDING_STOP, MODEL_UPLOAD_START, MODEL_UPLOAD_END, ACK, NACK, ERROR, READY. If a packet is lost or crc does not match, the current usecase is stopped and all input from serial is consumed and swallowed until it idles for at least 1s. Then the state is reset and the PC waits for the next command or input via serial.
- The teensy maintains a state (recording, listening, uploading)
- The button is debounced with a timing approach
- Use Teensy Audio Library queue objects (AudioRecordQueue) to gather audio in blocks.
- File indexing (next1.wav, next2.wav...) must be generated automatically by Python.
- Use TensorFlow's Speech Commands example for training a custom model.
- model upload. Teensy receives the model over USB serial and saves it to SD card. The PC needs to chunk the file on PC side in 512b blocks. Teensy receives 512 byte blocks and puts them together with a CRC each to reconstruct the final model on the SD card.
- Model Execution on Teensy. Use TFLM interpreter with the embedded model from SD card.Input comes from real-time MFCC of live mic audio.Implement post-processing of logits (e.g., smoothing, majority voting) and - important - be aware that the piano is playing while the words are spoken. 
- Teensy must act as USB HID keyboard. Define mapping: next/weiter → PAGE_DN,  back/zurück → PAGE_UP

- Python Console Interface: use a tool that does not require pressing <Enter> after input of a key. State-driven loop: Listen to keypresses and serial input quasi concurrently, but do not use threads but rather in a micrcontroller style in one global loop that constantly listens to the keyboard, then listens to serial input and processes it.

- Ensure constant training sample size by: Record for 2s. if the user presses for less time, pad with zero, if the user presses too long, trim to window size of of 2s. 
- During recording usecase, Teensy sends PCM 16 bit samples, after recording Teensy sends the total sample count. The PC is validating that the received sample number is actually received. 

- The PC records “background” which is  created by piano sound, silence is very low energy. Both modes are determined by the state on the PC side that is manually set by the menu. Background noise is not filtered out but stored as is. Define RMS threshold in the Python side to classify silence, which is calibrated in the code.

- allow another usecase "augmentation". This usecase takes all files from "silence" and "background" and mixes them with all sound files from back,next,weiter,zurück at SNR=5 and SNR=10, and creates more training snipets with a  name like dataset/next/next_5_aug1.wav. The augmented files are automatically used for training. augmented files go in the same data structure like the original files. So before training the augemntation usecase is automatically executed. 

- on the PC models are versioned with a number. When the PC uploaded the model, it takes the latest one.On upload, the PC renames model_vN.tflite to model.tflite before sending. Teensy always reads model.tflite.
- Teensy deletes or renames previous model only after CRC check passed.
- Debounce the inference as well by having a minimal wait after triggering PAGE_UP or PAGE_DN of 1s.
- Teensy reads SD card on boot to check if model.tflite exists. If yes, green LED is on and listening mode is started. If not, only recording or upload is allowed and green LED is off. As soon as a model is there, it switches to green listening mode.
- The Serial Log Format should be "[INFO] Recording started at t=123ms"

 Create a detailled plan as follows:
 - First show all concepts that you need to apply which I have not specified for review.
- Show the schematics of the PCB in ASCII art
- Show how to setup PlatformIO for the Teensy
- Show how to setup the PC (probably only python and Tensorflow for training)
- List the python program 
- List the Teensy firmware program

